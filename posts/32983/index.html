<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.0.0">
<link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/logo.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/logo.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/logo.png">
  <link rel="mask-icon" href="/images/logo.png" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha256-CTSx/A06dm1B063156EVh15m6Y67pAjZZaQc89LLSrU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-minimal.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"scorevictim.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.18.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":true,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="blog">
<meta property="og:title" content="机器学习期末Kaggle项目实践 —— House Prices - Advanced Regression Techniques">
<meta property="og:url" content="https://scorevictim.github.io/posts/32983/index.html">
<meta property="og:site_name" content="青崖之间">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://scorevictim.github.io/images/ML2631Project/cover.jpg">
<meta property="og:image" content="https://scorevictim.github.io/posts/32983/rawdist.png">
<meta property="og:image" content="https://scorevictim.github.io/posts/32983/logdist.png">
<meta property="og:image" content="https://scorevictim.github.io/posts/32983/pca.png">
<meta property="og:image" content="https://scorevictim.github.io/posts/32983/resultSCU.png">
<meta property="article:published_time" content="2022-05-25T10:46:09.000Z">
<meta property="article:modified_time" content="2023-11-12T06:39:18.402Z">
<meta property="article:author" content="分数受害者">
<meta property="article:tag" content="数据分析">
<meta property="article:tag" content="建模">
<meta property="article:tag" content="python">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="项目">
<meta property="article:tag" content="project">
<meta property="article:tag" content="Kaggle">
<meta property="article:tag" content="调参">
<meta property="article:tag" content="optuna">
<meta property="article:tag" content="regression">
<meta property="article:tag" content="回归">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://scorevictim.github.io/images/ML2631Project/cover.jpg">


<link rel="canonical" href="https://scorevictim.github.io/posts/32983/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://scorevictim.github.io/posts/32983/","path":"posts/32983/","title":"机器学习期末Kaggle项目实践 —— House Prices - Advanced Regression Techniques"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>机器学习期末Kaggle项目实践 —— House Prices - Advanced Regression Techniques | 青崖之间</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="青崖之间" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">青崖之间</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">北海虽赊，扶摇可接</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-留言板"><a href="/contact/" rel="section"><i class="fa fa-comment fa-fw"></i>留言板</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-友情链接"><a href="/friends/" rel="section"><i class="fa fa-link fa-fw"></i>友情链接</a></li><li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>站点地图</a></li><li class="menu-item menu-item-rss"><a href="/atom.xml" rel="section"><i class="fa fa-rss fa-fw"></i>RSS</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%89%8D%E8%A8%80"><span class="nav-number">1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%A7%A3%E9%87%8A%E6%80%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-Explotory-Data-Analysis"><span class="nav-number">2.</span> <span class="nav-text">解释性数据分析(Explotory Data Analysis)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8E%9F%E6%95%B0%E6%8D%AE%E6%A6%82%E5%86%B5"><span class="nav-number">2.1.</span> <span class="nav-text">原数据概况</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E6%A6%82%E5%86%B5"><span class="nav-number">2.2.</span> <span class="nav-text">特征概况</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E6%A6%82%E5%86%B5"><span class="nav-number">2.3.</span> <span class="nav-text">目标概况</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97%E4%B8%8E%E5%A1%AB%E8%A1%A5"><span class="nav-number">3.</span> <span class="nav-text">数据清洗与填补</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8D%95%E4%B8%80%E6%95%B0%E6%8D%AE%E5%88%97%E5%A4%84%E7%90%86"><span class="nav-number">3.1.</span> <span class="nav-text">单一数据列处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%B1%BB%E5%88%AB%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="nav-number">3.2.</span> <span class="nav-text">类别数据处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E5%AD%97%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="nav-number">3.3.</span> <span class="nav-text">数字数据处理</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B"><span class="nav-number">4.</span> <span class="nav-text">特征工程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A2%84%E5%A4%84%E7%90%86"><span class="nav-number">4.1.</span> <span class="nav-text">预处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%B1%BB%E5%88%AB%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B"><span class="nav-number">4.2.</span> <span class="nav-text">类别特征工程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B"><span class="nav-number">4.3.</span> <span class="nav-text">数字特征工程</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90-PCA"><span class="nav-number">4.3.1.</span> <span class="nav-text">主成分分析(PCA)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BB%9F%E4%B8%80%E5%88%97%E8%BD%AC%E6%8D%A2"><span class="nav-number">4.4.</span> <span class="nav-text">统一列转换</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E9%80%89%E5%8F%96%E5%8F%8A%E8%B0%83%E5%8F%82"><span class="nav-number">5.</span> <span class="nav-text">模型选取及调参</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9E%81%E9%99%90%E6%A2%AF%E5%BA%A6%E4%B8%8A%E5%8D%87%E6%A8%A1%E5%9E%8B"><span class="nav-number">5.1.</span> <span class="nav-text">极限梯度上升模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E6%A8%A1%E5%9E%8B"><span class="nav-number">5.2.</span> <span class="nav-text">随机森林模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BD%BB%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8A%E5%8D%87%E6%A8%A1%E5%9E%8B"><span class="nav-number">5.3.</span> <span class="nav-text">轻量梯度上升模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BC%B9%E5%8A%9B%E7%BD%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="nav-number">5.4.</span> <span class="nav-text">弹力网回归模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A5%97%E7%B4%A2%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="nav-number">5.5.</span> <span class="nav-text">套索回归模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B2%AD%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="nav-number">5.6.</span> <span class="nav-text">岭回归模型</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E5%A0%86%E5%8F%A0%E4%B8%8E%E6%B7%B7%E5%90%88"><span class="nav-number">6.</span> <span class="nav-text">模型堆叠与混合</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E5%A0%86%E5%8F%A0-Stacking"><span class="nav-number">6.1.</span> <span class="nav-text">模型堆叠(Stacking)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E6%B7%B7%E5%90%88-Blending"><span class="nav-number">6.2.</span> <span class="nav-text">模型混合(Blending)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BB%93%E6%9E%9C%E8%BE%93%E5%87%BA"><span class="nav-number">7.</span> <span class="nav-text">结果输出</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="分数受害者"
      src="/uploads/avatar.jpg">
  <p class="site-author-name" itemprop="name">分数受害者</p>
  <div class="site-description" itemprop="description">人生如痴人说梦，充满着喧哗与骚动，却没有任何意义</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">36</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">88</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://scorevictim.github.io/posts/32983/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.jpg">
      <meta itemprop="name" content="分数受害者">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="青崖之间">
      <meta itemprop="description" content="人生如痴人说梦，充满着喧哗与骚动，却没有任何意义">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="机器学习期末Kaggle项目实践 —— House Prices - Advanced Regression Techniques | 青崖之间">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          机器学习期末Kaggle项目实践 —— House Prices - Advanced Regression Techniques
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-25 03:46:09" itemprop="dateCreated datePublished" datetime="2022-05-25T03:46:09-07:00">2022-05-25</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-11-11 22:39:18" itemprop="dateModified" datetime="2023-11-11T22:39:18-08:00">2023-11-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">学习笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>29k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>27 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p><img src="/images/ML2631Project/cover.jpg" alt="banner"></p>
<span id="more"></span>

<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>如果有关注本人近期的博文，就知道本学渣最近在啃机器学习这门课程，这门课显然对于本人这种文科生来说有些太硬了，但无论如何，通过忽略不少的底层数学原理及推导，这几个月也算跌跌撞撞学下来了。</p>
<p>不知不觉，也就到了本学期的末尾，本人自然便要面对这门课的期末考试，而教授将我们的期末分为了两部分：笔试和比赛。笔试部分这里就不多提了，主要就是考察之前三篇笔记中的所有概念，而期末的另一部分，则是到Kaggle上打比赛，最终成绩根据排名给出。本学期给我们分配到的比赛为：<a target="_blank" rel="noopener" href="https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview">House Prices - Advanced Regression Techniques</a> ，主要内容是根据特征数据，建模并预测某地的房价走势。</p>
<p>由于本人智力水平一般，再加上这门课的速度实在是太快，因此时常会忘记某些概念和用法。故而在此开一篇文章，单独记录下课程期末项目中每一步的思路，以使整体框架逻辑清晰。</p>
<p>同时，鉴于本人只是初学者入门水平，文中的方法难免存在各种问题，如果有大佬发现任何值得改进的地方，务必在评论区不吝指教，本人将感激不尽！</p>
<p>文中的所有代码已经托管到了我的Github仓库，可以在这里找到：<a target="_blank" rel="noopener" href="https://github.com/scorevictim/Kaggle_House-Prices---Advanced-Regression-Techniques/blob/master/ML2631Project.ipynb">Kaggle House Price Competition</a> </p>
<hr>
<h2 id="解释性数据分析-Explotory-Data-Analysis"><a href="#解释性数据分析-Explotory-Data-Analysis" class="headerlink" title="解释性数据分析(Explotory Data Analysis)"></a>解释性数据分析(Explotory Data Analysis)</h2><p>EDA这一部分，实在是有点鸡肋，做了没什么大用，但不做又感觉少了点什么……</p>
<h3 id="原数据概况"><a href="#原数据概况" class="headerlink" title="原数据概况"></a>原数据概况</h3><p>首先我们读取数据集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line">pd.set_option(<span class="string">&#x27;display.max_columns&#x27;</span>, <span class="number">500</span>)</span><br><span class="line">test_raw = pd.read_csv(<span class="string">&quot;input/test.csv&quot;</span>)</span><br><span class="line">train_raw = pd.read_csv(<span class="string">&quot;input/train.csv&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>通过观察列名，可知其中有一行<code>Id</code>列，对于预测没有用处，我们首先删去这一列，同时要备份留作后用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Backup</span></span><br><span class="line">train_ID = train_raw[<span class="string">&#x27;Id&#x27;</span>]</span><br><span class="line">test_ID = test_raw[<span class="string">&#x27;Id&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Drop</span></span><br><span class="line">train_raw.drop(<span class="string">&quot;Id&quot;</span>, axis = <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br><span class="line">test_raw.drop(<span class="string">&quot;Id&quot;</span>, axis = <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>这之后，训练集变为80列，测试集变为79列，多出来的一列为需要预测的SalePrice。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train_raw.shape</span><br><span class="line"><span class="comment"># (1460, 80)</span></span><br><span class="line"></span><br><span class="line">test_raw.shape</span><br><span class="line"><span class="comment"># (1459, 79)</span></span><br></pre></td></tr></table></figure>

<h3 id="特征概况"><a href="#特征概况" class="headerlink" title="特征概况"></a>特征概况</h3><p>原始数据中，特征分为分类数据和数字数据。</p>
<p>分别获取列名：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">categoricalColumns = train_raw.select_dtypes(include=[<span class="string">&#x27;object&#x27;</span>]).columns.to_list()</span><br><span class="line">numericalColumns = train_raw._get_numeric_data().columns.to_list()</span><br></pre></td></tr></table></figure>

<p>对于分类特征，原始数据中有43列：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_cat_raw = train_raw[categoricalColumns]</span><br><span class="line">train_cat_raw</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1460 rows × 43 columns</span></span><br></pre></td></tr></table></figure>

<p>对于数字特征，原始数据中有37列：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_num_raw = train_raw[numericalColumns]</span><br><span class="line">train_num_raw</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1460 rows × 37 columns</span></span><br></pre></td></tr></table></figure>

<h3 id="目标概况"><a href="#目标概况" class="headerlink" title="目标概况"></a>目标概况</h3><p>首先我们获取目标数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">target = <span class="string">&quot;SalePrice&quot;</span></span><br><span class="line">y_train_raw = train_raw[target]</span><br></pre></td></tr></table></figure>

<p>对其进行一些简单可视化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> matplotlib.pyplot <span class="keyword">import</span> figure</span><br><span class="line">figure(figsize=(<span class="number">5</span>, <span class="number">10</span>))</span><br><span class="line">sns.boxplot(data = y_train_raw)</span><br></pre></td></tr></table></figure>

<img src="/posts/32983/rawdist.png" class="" title="raw dist">

<p>可见其并非正态分布，而对于线性模型而言，需要数据符合正态分布，于是我们对其对数化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.displot(data = np.log1p(y_train_raw), kde=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<img src="/posts/32983/logdist.png" class="" title="log dist">

<p>将其存入<code>y_train</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_train = np.log1p(y_train_raw)</span><br></pre></td></tr></table></figure>

<p>然后观察变量间的相关性：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pylab <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.pyplot <span class="keyword">import</span> figure</span><br><span class="line">%matplotlib inline</span><br><span class="line">figure(figsize=(<span class="number">30</span>, <span class="number">15</span>))</span><br><span class="line">mask = np.triu(np.ones_like(train_num_raw.corr(), dtype=<span class="built_in">bool</span>))</span><br><span class="line">heatmap1 = sns.heatmap(train_num_raw.corr(), vmin=-<span class="number">1</span>, vmax=<span class="number">1</span>, annot=<span class="literal">True</span>, cmap=<span class="string">&#x27;BrBG&#x27;</span>, mask=mask)</span><br><span class="line">heatmap1.set_title(<span class="string">&#x27;Train Column Correlation Heatmap&#x27;</span>, fontdict=&#123;<span class="string">&#x27;fontsize&#x27;</span>:<span class="number">18</span>&#125;, pad=<span class="number">16</span>)</span><br></pre></td></tr></table></figure>

<p>图的体积比较大，就不在这里截图了，可以到我的Github上查看详细的图，不过其实这一步没有什么用。</p>
<hr>
<h2 id="数据清洗与填补"><a href="#数据清洗与填补" class="headerlink" title="数据清洗与填补"></a>数据清洗与填补</h2><p>不难发现，这一数据集存在较多空值，在这一章节，我们对数据集中的空值进行统一处理。</p>
<p>首先为了减少工作量，我们合并训练、测试集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_raw = pd.concat((train_raw.drop(target, axis=<span class="number">1</span>), test_raw), ignore_index=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>之后凡是不会涉及到数据溢出的填补操作，我们都在<code>all_raw</code>之上进行。</p>
<h3 id="单一数据列处理"><a href="#单一数据列处理" class="headerlink" title="单一数据列处理"></a>单一数据列处理</h3><p>当某列特征的数据几乎完全只有一个值时，我们可以认为这列对于模型没有贡献，因此对其进行删除操作。</p>
<p>这里本人采用的判断标准是：如果某列的某个值占比超过了该列的99%，则判定该列为单一数据列。</p>
<p>代码实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># If a value accounts for more than 99% of one column, we define the column as single value column, and we can drop it.</span></span><br><span class="line"></span><br><span class="line">singleValueColumns = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> all_raw.columns.unique().tolist():</span><br><span class="line">    <span class="keyword">if</span> all_raw[i].value_counts(normalize=<span class="literal">True</span>).iloc[<span class="number">0</span>] &gt; <span class="number">0.99</span>:</span><br><span class="line">        singleValueColumns.append(i)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show single valew columns</span></span><br><span class="line">singleValueColumns</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line"><span class="comment"># [&#x27;Street&#x27;, &#x27;Utilities&#x27;, &#x27;PoolArea&#x27;]</span></span><br></pre></td></tr></table></figure>

<p>接下来只需将上述列删除即完成这一步的处理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_raw = all_raw.drop(singleValueColumns, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<h3 id="类别数据处理"><a href="#类别数据处理" class="headerlink" title="类别数据处理"></a>类别数据处理</h3><p>对于类别数据，由于网站提供的数据描述文件中提供了一部分的特征为<code>Na</code>的解释，我们将其直接应用，而对于没有提供描述的，我们基于常识做一些假设，将Na填补为已有数据，具体的假设可以在我托管在Github上的源代码中找到。</p>
<p>总之我们建立一个这样的填补索引列：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Make Na conversion list</span></span><br><span class="line"></span><br><span class="line">cat_na_conversion = [(<span class="string">&quot;MasVnrType&quot;</span>, <span class="string">&quot;None&quot;</span>),</span><br><span class="line">                     (<span class="string">&quot;BsmtQual&quot;</span>, <span class="string">&quot;None&quot;</span>), </span><br><span class="line">                     (<span class="string">&quot;Electrical&quot;</span>, <span class="string">&quot;SBrkr&quot;</span>),</span><br><span class="line">                     (<span class="string">&quot;BsmtCond&quot;</span>, <span class="string">&quot;None&quot;</span>),</span><br><span class="line">                     (<span class="string">&quot;BsmtExposure&quot;</span>, <span class="string">&quot;None&quot;</span>),</span><br><span class="line">                     (<span class="string">&quot;BsmtFinType1&quot;</span>, <span class="string">&quot;None&quot;</span>),</span><br><span class="line">                     (<span class="string">&quot;BsmtFinType2&quot;</span>, <span class="string">&quot;None&quot;</span>),</span><br><span class="line">                     (<span class="string">&quot;CentralAir&quot;</span>, <span class="string">&quot;N&quot;</span>),</span><br><span class="line">                     (<span class="string">&quot;Condition1&quot;</span>, <span class="string">&quot;Norm&quot;</span>), </span><br><span class="line">                     (<span class="string">&quot;Condition2&quot;</span>, <span class="string">&quot;Norm&quot;</span>),</span><br><span class="line">                     (<span class="string">&quot;ExterCond&quot;</span>, <span class="string">&quot;TA&quot;</span>),</span><br><span class="line">                     (<span class="string">&quot;ExterQual&quot;</span>, <span class="string">&quot;TA&quot;</span>), </span><br><span class="line">                     (<span class="string">&quot;FireplaceQu&quot;</span>, <span class="string">&quot;None&quot;</span>),</span><br><span class="line">                     (<span class="string">&quot;GarageType&quot;</span>, <span class="string">&quot;None&quot;</span>), </span><br><span class="line">                     (<span class="string">&quot;GarageFinish&quot;</span>, <span class="string">&quot;None&quot;</span>), </span><br><span class="line">                     (<span class="string">&quot;GarageQual&quot;</span>, <span class="string">&quot;None&quot;</span>), </span><br><span class="line">                     (<span class="string">&quot;GarageCond&quot;</span>, <span class="string">&quot;None&quot;</span>), </span><br><span class="line">                     (<span class="string">&quot;HeatingQC&quot;</span>, <span class="string">&quot;TA&quot;</span>), </span><br><span class="line">                     (<span class="string">&quot;KitchenQual&quot;</span>, <span class="string">&quot;TA&quot;</span>), </span><br><span class="line">                     (<span class="string">&quot;Functional&quot;</span>, <span class="string">&quot;Typ&quot;</span>), </span><br><span class="line">                     (<span class="string">&quot;MSZoning&quot;</span>, <span class="string">&quot;None&quot;</span>),</span><br><span class="line">                     (<span class="string">&quot;Exterior1st&quot;</span>, <span class="string">&quot;VinylSd&quot;</span>), </span><br><span class="line">                     (<span class="string">&quot;Exterior2nd&quot;</span>, <span class="string">&quot;VinylSd&quot;</span>), </span><br><span class="line">                     (<span class="string">&quot;SaleType&quot;</span>, <span class="string">&quot;WD&quot;</span>),</span><br><span class="line">                     (<span class="string">&quot;PoolQC&quot;</span>, <span class="string">&quot;None&quot;</span>),</span><br><span class="line">                     (<span class="string">&quot;Fence&quot;</span>, <span class="string">&quot;None&quot;</span>),</span><br><span class="line">                     (<span class="string">&quot;MiscFeature&quot;</span>, <span class="string">&quot;None&quot;</span>),</span><br><span class="line">                     (<span class="string">&quot;Alley&quot;</span>, <span class="string">&quot;None&quot;</span>)]</span><br></pre></td></tr></table></figure>

<p>然后进行遍历列名的填补：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> colName, toStr <span class="keyword">in</span> cat_na_conversion:</span><br><span class="line">    all_raw.loc[:, colName] = all_raw.loc[:, colName].fillna(toStr)</span><br></pre></td></tr></table></figure>

<h3 id="数字数据处理"><a href="#数字数据处理" class="headerlink" title="数字数据处理"></a>数字数据处理</h3><p>首先我们筛选出所有的需要处理的列名：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Find numerical colimns with missing values</span></span><br><span class="line"></span><br><span class="line">num_na_col = all_raw.columns[all_raw.isna().<span class="built_in">any</span>()].tolist()</span><br><span class="line">num_na_col</span><br><span class="line"></span><br><span class="line"><span class="comment">#[&#x27;LotFrontage&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;MasVnrArea&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;BsmtFinSF1&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;BsmtFinSF2&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;BsmtUnfSF&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;TotalBsmtSF&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;BsmtFullBath&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;BsmtHalfBath&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;GarageYrBlt&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;GarageCars&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;GarageArea&#x27;]</span></span><br></pre></td></tr></table></figure>

<p>其中，除了<code>&#39;LotFrontage&#39;</code>一列外，其余的其实都和我们上一步填补的分类特征相关，我们也可以做相同的假设，将其中所有的<code>Na</code>填补为<code>0</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">num_to_zero_col = num_na_col.copy()</span><br><span class="line">num_to_zero_col.remove(<span class="string">&#x27;LotFrontage&#x27;</span>)</span><br><span class="line">num_to_zero_col</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> num_to_zero_col:</span><br><span class="line">    all_raw[col] = all_raw[col].fillna(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">all_raw.columns[all_raw.isna().<span class="built_in">any</span>()].tolist()</span><br><span class="line"></span><br><span class="line"><span class="comment"># [&#x27;LotFrontage&#x27;]</span></span><br></pre></td></tr></table></figure>

<p>处理完后仅剩<code>&#39;LotFrontage&#39;</code>一列存在空值，我们接下来对其进行处理：</p>
<p>这里也用了一个假设，我们认为处于同一个<code>Neighbor</code>下的房子有相似的<code>LotFrontage</code>值，所以我们可以先以<code>Neighbor</code>归类，然后用中位数填补。</p>
<p>但这里如果直接用<code>all_raw</code>来做处理，我们会将训练集的数据填到测试集中，这会导致数据泄露，因此我们首先将其重新分为两部分：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train_imputed[<span class="string">&quot;LotFrontage&quot;</span>] = train_raw_Lot.groupby(<span class="string">&quot;Neighborhood&quot;</span>)[<span class="string">&quot;LotFrontage&quot;</span>].transform(</span><br><span class="line">    <span class="keyword">lambda</span> x: x.fillna(x.median()))</span><br><span class="line"></span><br><span class="line">test_imputed[<span class="string">&quot;LotFrontage&quot;</span>] = test_raw_Lot.groupby(<span class="string">&quot;Neighborhood&quot;</span>)[<span class="string">&quot;LotFrontage&quot;</span>].transform(</span><br><span class="line">    <span class="keyword">lambda</span> x: x.fillna(x.median()))</span><br></pre></td></tr></table></figure>

<p>此时我们便得到了填补后的数据，可见其不再有空值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">train_imputed.isna().<span class="built_in">sum</span>().<span class="built_in">max</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 0 </span></span><br><span class="line"></span><br><span class="line">test_imputed.isna().<span class="built_in">sum</span>().<span class="built_in">max</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 0 </span></span><br></pre></td></tr></table></figure>

<hr>
<h2 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h2><h3 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h3><p>我们留意到：对于原数据中的某些数字特征，其实际表示的却是分类（如建造年份），而分类数据也同理，因此我们考虑将这些特征转换为其实际对应的格式。</p>
<p>有分类特征的数字列名为：</p>
<p><code>YrSold</code> <code>MoSold</code> <code>GarageYrBlt</code> <code>MSSubClass</code> <code>OverallCond</code> <code>YearBuilt</code></p>
<p>这里为了方便处理，我们还是将其合并为整表：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># .loc[:len(train_raw)-1, :]</span></span><br><span class="line"><span class="comment"># .loc[len(test_raw)+1:, :]</span></span><br><span class="line">all_imputed = pd.concat((train_imputed, test_imputed), ignore_index=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>然后将上述列进行转换：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">num_to_cat_list = [<span class="string">&quot;GarageYrBlt&quot;</span>, <span class="string">&quot;MSSubClass&quot;</span>, <span class="string">&quot;OverallCond&quot;</span>, <span class="string">&quot;YrSold&quot;</span>, <span class="string">&quot;MoSold&quot;</span>, <span class="string">&quot;YearBuilt&quot;</span>, <span class="string">&quot;YearRemodAdd&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> num_to_cat_list:</span><br><span class="line">    all_imputed[i] = all_imputed[i].astype(<span class="built_in">str</span>)</span><br></pre></td></tr></table></figure>

<p>同时，我在网上看到其它的一些大佬对于某些原始列进行运算，以制造新特征，我觉得挺有道理，就复刻了一些过来：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">all_imputed[<span class="string">&#x27;TotalArea&#x27;</span>] = all_imputed[<span class="string">&#x27;TotalBsmtSF&#x27;</span>] + all_imputed[<span class="string">&#x27;1stFlrSF&#x27;</span>] + all_imputed[<span class="string">&#x27;2ndFlrSF&#x27;</span>]</span><br><span class="line"></span><br><span class="line">all_imputed[<span class="string">&#x27;TotalBath&#x27;</span>] = (all_imputed[<span class="string">&#x27;FullBath&#x27;</span>] + (<span class="number">0.5</span> * all_imputed[<span class="string">&#x27;HalfBath&#x27;</span>]) +</span><br><span class="line">                               all_imputed[<span class="string">&#x27;BsmtFullBath&#x27;</span>] + (<span class="number">0.5</span> * all_imputed[<span class="string">&#x27;BsmtHalfBath&#x27;</span>]))</span><br><span class="line">all_imputed[<span class="string">&#x27;TotalBsmtbath&#x27;</span>] = all_imputed[<span class="string">&#x27;BsmtFullBath&#x27;</span>] + (<span class="number">0.5</span> * all_imputed[<span class="string">&#x27;BsmtHalfBath&#x27;</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">all_imputed[<span class="string">&#x27;TotalPorchSF&#x27;</span>] = (all_imputed[<span class="string">&#x27;OpenPorchSF&#x27;</span>] + all_imputed[<span class="string">&#x27;3SsnPorch&#x27;</span>] +</span><br><span class="line">                            all_imputed[<span class="string">&#x27;EnclosedPorch&#x27;</span>] + all_imputed[<span class="string">&#x27;ScreenPorch&#x27;</span>] + all_imputed[<span class="string">&#x27;WoodDeckSF&#x27;</span>])</span><br><span class="line"></span><br><span class="line">allData = all_imputed.drop([<span class="string">&#x27;TotalBsmtSF&#x27;</span>, <span class="string">&#x27;1stFlrSF&#x27;</span>, <span class="string">&#x27;2ndFlrSF&#x27;</span>, <span class="string">&#x27;FullBath&#x27;</span>, <span class="string">&#x27;HalfBath&#x27;</span>, <span class="string">&#x27;BsmtFullBath&#x27;</span>, <span class="string">&#x27;BsmtHalfBath&#x27;</span>, <span class="string">&#x27;OpenPorchSF&#x27;</span>, <span class="string">&#x27;3SsnPorch&#x27;</span>, <span class="string">&#x27;EnclosedPorch&#x27;</span>, <span class="string">&#x27;ScreenPorch&#x27;</span>, <span class="string">&#x27;WoodDeckSF&#x27;</span>])</span><br></pre></td></tr></table></figure>

<p>然后我们便可以拿到预处理后的训练+测试集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train = allData.loc[:<span class="built_in">len</span>(train_raw)-<span class="number">1</span>, :]</span><br><span class="line">X_test = allData.loc[<span class="built_in">len</span>(test_raw)+<span class="number">1</span>:, :]</span><br></pre></td></tr></table></figure>

<h3 id="类别特征工程"><a href="#类别特征工程" class="headerlink" title="类别特征工程"></a>类别特征工程</h3><p>获取所有的类别列：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">cat_features = allData.select_dtypes(include=[<span class="string">&#x27;object&#x27;</span>]).columns.to_list()</span><br><span class="line"></span><br><span class="line"><span class="comment"># [&#x27;MSSubClass&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;MSZoning&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;Alley&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;LotShape&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;LandContour&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;LotConfig&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;LandSlope&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;Neighborhood&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;Condition1&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;Condition2&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;BldgType&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;HouseStyle&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;OverallCond&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;YearBuilt&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;RoofStyle&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;RoofMatl&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;Exterior1st&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;Exterior2nd&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;MasVnrType&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;ExterQual&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;ExterCond&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;Foundation&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;BsmtQual&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;BsmtCond&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;BsmtExposure&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;BsmtFinType1&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;BsmtFinType2&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;Heating&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;HeatingQC&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;CentralAir&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;Electrical&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;KitchenQual&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;Functional&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;FireplaceQu&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;GarageType&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;GarageYrBlt&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;GarageFinish&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;GarageQual&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;GarageCond&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;PavedDrive&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;PoolQC&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;Fence&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;MiscFeature&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;MoSold&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;YrSold&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;SaleType&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;SaleCondition&#x27;]</span></span><br></pre></td></tr></table></figure>

<p>对于其中的某些没有很多不同数据的列，我们可以简单的使用独热编码，因为这些列不会造成过大的稀疏矩阵，对于其中的表示大小的分类，我们考虑使用顺序编码，而剩下来的所有列，我们用目标编码。首先我们筛选出这些列：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ordinal_cat_features = [<span class="string">&#x27;FireplaceQu&#x27;</span>, <span class="string">&#x27;BsmtQual&#x27;</span>, <span class="string">&#x27;BsmtCond&#x27;</span>, <span class="string">&#x27;GarageQual&#x27;</span>, <span class="string">&#x27;GarageCond&#x27;</span>, <span class="string">&#x27;ExterQual&#x27;</span>, <span class="string">&#x27;ExterCond&#x27;</span>, <span class="string">&#x27;HeatingQC&#x27;</span>, <span class="string">&#x27;PoolQC&#x27;</span>, <span class="string">&#x27;KitchenQual&#x27;</span>, <span class="string">&#x27;BsmtFinType1&#x27;</span>,</span><br><span class="line">                        <span class="string">&#x27;BsmtFinType2&#x27;</span>, <span class="string">&#x27;Functional&#x27;</span>, <span class="string">&#x27;Fence&#x27;</span>, <span class="string">&#x27;BsmtExposure&#x27;</span>, <span class="string">&#x27;GarageFinish&#x27;</span>, <span class="string">&#x27;LandSlope&#x27;</span>, <span class="string">&#x27;LotShape&#x27;</span>, <span class="string">&#x27;MSSubClass&#x27;</span>, <span class="string">&#x27;OverallCond&#x27;</span>, <span class="string">&quot;YrSold&quot;</span>, <span class="string">&quot;MoSold&quot;</span>, <span class="string">&quot;YearBuilt&quot;</span>, <span class="string">&quot;YearRemodAdd&quot;</span>]</span><br><span class="line"></span><br><span class="line">onehot_cat_features = [<span class="string">&#x27;CentralAir&#x27;</span>, <span class="string">&#x27;PavedDrive&#x27;</span>]</span><br><span class="line"></span><br><span class="line">target_cat_features = <span class="built_in">list</span>(<span class="built_in">set</span>(cat_features) - <span class="built_in">set</span>(ordinal_cat_features) - <span class="built_in">set</span>(onehot_cat_features))</span><br></pre></td></tr></table></figure>

<p>有了列表以后，我们便可以在之后用列转换来处理。</p>
<blockquote>
<p>P.S. 后来的调教中，我发现顺序编码效果一般，于是后来就只用了独热和目标编码。</p>
</blockquote>
<h3 id="数字特征工程"><a href="#数字特征工程" class="headerlink" title="数字特征工程"></a>数字特征工程</h3><p>获取所有数字列：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">num_features = allData._get_numeric_data().columns.to_list()</span><br><span class="line"></span><br><span class="line"><span class="comment"># [&#x27;LotFrontage&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;LotArea&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;OverallQual&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;MasVnrArea&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;BsmtFinSF1&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;BsmtFinSF2&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;BsmtUnfSF&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;LowQualFinSF&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;GrLivArea&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;BedroomAbvGr&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;KitchenAbvGr&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;TotRmsAbvGrd&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;Fireplaces&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;GarageCars&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;GarageArea&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;MiscVal&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;TotalArea&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;TotalBath&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;TotalBsmtbath&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;TotalPorchSF&#x27;]</span></span><br></pre></td></tr></table></figure>

<p>这里也可以看一下数字列与目标列的相关度：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">pd.concat([X_train[num_features], y_train], axis=<span class="number">1</span>)</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pylab <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.pyplot <span class="keyword">import</span> figure</span><br><span class="line">%matplotlib inline</span><br><span class="line">figure(figsize=(<span class="number">30</span>, <span class="number">15</span>))</span><br><span class="line">mask = np.triu(np.ones_like(pd.concat([X_train[num_features], y_train], axis=<span class="number">1</span>).corr(), dtype=<span class="built_in">bool</span>))</span><br><span class="line">heatmap1 = sns.heatmap(pd.concat([X_train[num_features], y_train], axis=<span class="number">1</span>).corr(), vmin=-<span class="number">1</span>, vmax=<span class="number">1</span>, annot=<span class="literal">True</span>, cmap=<span class="string">&#x27;BrBG&#x27;</span>, mask=mask)</span><br><span class="line">heatmap1.set_title(<span class="string">&#x27;Train Column Correlation Heatmap&#x27;</span>, fontdict=&#123;<span class="string">&#x27;fontsize&#x27;</span>:<span class="number">18</span>&#125;, pad=<span class="number">16</span>)</span><br></pre></td></tr></table></figure>
<p>也不截图了，可以到我的Github上看，总之就是相关性都挺高的。</p>
<h4 id="主成分分析-PCA"><a href="#主成分分析-PCA" class="headerlink" title="主成分分析(PCA)"></a>主成分分析(PCA)</h4><p>考虑对原数据进行PCA降维：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> make_pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> RobustScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line">pca_scaled = make_pipeline(RobustScaler(), </span><br><span class="line">                           MinMaxScaler(),</span><br><span class="line">                           PCA(n_components=<span class="built_in">len</span>(num_features)))</span><br><span class="line"></span><br><span class="line">X_pca_scaled = pca_scaled.fit_transform(X_train[num_features])</span><br><span class="line"></span><br><span class="line">xi = np.arange(<span class="number">1</span>, <span class="built_in">len</span>(num_features)+<span class="number">1</span>, step=<span class="number">1</span>)</span><br><span class="line">y = np.cumsum(pca_scaled.named_steps[<span class="string">&#x27;pca&#x27;</span>].explained_variance_ratio_)</span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&quot;figure.figsize&quot;</span>] = (<span class="number">15</span>,<span class="number">9</span>)</span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line"></span><br><span class="line">plt.plot(xi, y, marker=<span class="string">&#x27;o&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, color=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Number of Components&#x27;</span>)</span><br><span class="line">plt.xticks(np.arange(<span class="number">0</span>, <span class="built_in">len</span>(num_features), step=<span class="number">1</span>))</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Cumulative variance (%)&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;The number of components needed to explain variance&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.axhline(y=<span class="number">0.95</span>, color=<span class="string">&#x27;r&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">plt.text(<span class="number">0.5</span>, <span class="number">0.85</span>, <span class="string">&#x27;95% cut-off threshold&#x27;</span>, color = <span class="string">&#x27;red&#x27;</span>, fontsize=<span class="number">16</span>)</span><br><span class="line"></span><br><span class="line">ax.grid(axis=<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="/posts/32983/pca.png" class="" title="PCA">

<p>可以看出当主成分为12个时，便可以解释原19维数据95%的方差，于是我们便可以将PCA中的<code>n_component</code>设为12</p>
<blockquote>
<p>P.S. 后续的分析中发现在本人这一套的建模模式下，PCA没有显著好处，且会降低模型性能，于是最后没有采取PCA。</p>
</blockquote>
<h3 id="统一列转换"><a href="#统一列转换" class="headerlink" title="统一列转换"></a>统一列转换</h3><p>将前文所述的所有方法打包为一个列转换管道pipeline：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.compose <span class="keyword">import</span> ColumnTransformer</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> RobustScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OrdinalEncoder</span><br><span class="line"><span class="keyword">from</span> category_encoders.target_encoder <span class="keyword">import</span> TargetEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line">preprocess = ColumnTransformer(transformers=[(<span class="string">&#x27;num&#x27;</span>,</span><br><span class="line">                                              Pipeline(steps=[(<span class="string">&#x27;scaler1&#x27;</span>, RobustScaler()),</span><br><span class="line">                                                              (<span class="string">&#x27;scaler2&#x27;</span>, StandardScaler()),</span><br><span class="line">                                                             <span class="comment">#(&#x27;scaler3&#x27;,MinMaxScaler()),</span></span><br><span class="line">                                                             <span class="comment">#(&#x27;pca&#x27;, PCA(n_components=12))</span></span><br><span class="line">                                                              ]),</span><br><span class="line">                                              num_features),</span><br><span class="line">                                                 </span><br><span class="line">                                              (<span class="string">&#x27;OneHotCat&#x27;</span>,</span><br><span class="line">                                              Pipeline(steps=[(<span class="string">&#x27;encoder1&#x27;</span>, OneHotEncoder(handle_unknown=<span class="string">&#x27;ignore&#x27;</span>))</span><br><span class="line">													   ]),</span><br><span class="line">                                              onehot_cat_features),</span><br><span class="line">                                              (<span class="string">&#x27;TargetCat&#x27;</span>,</span><br><span class="line">                                              Pipeline(steps=[(<span class="string">&#x27;encoder2&#x27;</span>, TargetEncoder()),</span><br><span class="line">                                                              (<span class="string">&#x27;scaler21&#x27;</span>, RobustScaler()),</span><br><span class="line">                                                              (<span class="string">&#x27;scaler22&#x27;</span>, StandardScaler()),</span><br><span class="line">                                                             <span class="comment">#(&#x27;scaler23&#x27;, MinMaxScaler())</span></span><br><span class="line">                                                              ]),</span><br><span class="line">                                              target_cat_features),</span><br><span class="line">                                              (<span class="string">&#x27;OrdinalCat&#x27;</span>,</span><br><span class="line">                                              Pipeline(steps=[<span class="comment">#(&#x27;encoder3&#x27;, OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;, unknown_value=-1)),</span></span><br><span class="line">                                                               (<span class="string">&#x27;encoder2&#x27;</span>, TargetEncoder()),</span><br><span class="line">                                                               (<span class="string">&#x27;scaler31&#x27;</span>, RobustScaler()),</span><br><span class="line">                                                               (<span class="string">&#x27;scaler32&#x27;</span>, StandardScaler()),</span><br><span class="line">                                                              <span class="comment">#(&#x27;scaler33&#x27;, MinMaxScaler())</span></span><br><span class="line">                                                               ]),</span><br><span class="line">                                              ordinal_cat_features)</span><br><span class="line">                                              ])</span><br></pre></td></tr></table></figure>

<p>至此，预处理管道就搭建完了。</p>
<hr>
<h2 id="模型选取及调参"><a href="#模型选取及调参" class="headerlink" title="模型选取及调参"></a>模型选取及调参</h2><p>这一部分中，我选取了6个模型：随机森林、极限梯度上升、弹力网回归、轻量梯度上升、套索回归、岭回归。</p>
<p>而调参环节，我采用的调参器是<code>optuna</code>，这是一个声称有很好的算法的调参框架。而实际使用上，相比网格搜索，它的性能也高很多，且可以看到调参进度，避免了使用<code>GridSearch</code>框架时看不出程序是否卡死的烦恼；同时，它还自带一些可视化方法，可以直观地看出调参过程。当然对于其具体的实现细节，本人并没有深入了解，这里只记录一下使用方法。</p>
<p><code>optuna</code>调参的一些操作要感谢<a target="_blank" rel="noopener" href="https://github.com/PrettyMeng">PrettyMeng</a> 大佬的帮助。</p>
<p><code>optuna</code>安装：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install optuna</span><br></pre></td></tr></table></figure>

<p>加载模型库：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Lasso,  Ridge</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold, cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> optuna</span><br></pre></td></tr></table></figure>

<h3 id="极限梯度上升模型"><a href="#极限梯度上升模型" class="headerlink" title="极限梯度上升模型"></a>极限梯度上升模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">objective_xgb</span>(<span class="params">trial, X_train, y_train_raw</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Objective function to tune an `XGBRegressor` model.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    y_train = np.log1p(y_train_raw)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Define Parameter Grid to Tune</span></span><br><span class="line">    params = &#123;</span><br><span class="line">        <span class="string">&#x27;n_estimators&#x27;</span>: trial.suggest_int(<span class="string">&quot;n_estimators&quot;</span>, <span class="number">100</span>, <span class="number">5000</span>),</span><br><span class="line">        <span class="string">&#x27;reg_alpha&#x27;</span>: trial.suggest_loguniform(<span class="string">&quot;reg_alpha&quot;</span>, <span class="number">1e-10</span>, <span class="number">1e-1</span>),</span><br><span class="line">        <span class="string">&#x27;reg_lambda&#x27;</span>: trial.suggest_loguniform(<span class="string">&quot;reg_lambda&quot;</span>, <span class="number">1e-8</span>, <span class="number">100.0</span>),</span><br><span class="line">        <span class="string">&quot;subsample&quot;</span>: trial.suggest_float(<span class="string">&quot;subsample&quot;</span>, <span class="number">0.8</span>, <span class="number">1.0</span>, step=<span class="number">0.001</span>),</span><br><span class="line">        <span class="string">&quot;learning_rate&quot;</span>: trial.suggest_float(<span class="string">&quot;learning_rate&quot;</span>, <span class="number">0.01</span>, <span class="number">0.1</span>, log=<span class="literal">True</span>),</span><br><span class="line">        <span class="string">&#x27;max_depth&#x27;</span>: trial.suggest_int(<span class="string">&quot;max_depth&quot;</span>, <span class="number">2</span>, <span class="number">9</span>),</span><br><span class="line">        <span class="string">&#x27;colsample_bytree&#x27;</span>: trial.suggest_float(<span class="string">&#x27;colsample_bytree&#x27;</span>, <span class="number">0</span>, <span class="number">1.0</span>, step=<span class="number">0.05</span>),</span><br><span class="line">        <span class="string">&#x27;colsample_bylevel&#x27;</span>: trial.suggest_float(<span class="string">&#x27;colsample_bylevel&#x27;</span>, <span class="number">0.5</span>, <span class="number">1.0</span>, step=<span class="number">0.005</span>),</span><br><span class="line">        <span class="string">&#x27;colsample_bynode&#x27;</span>: trial.suggest_float(<span class="string">&#x27;colsample_bynode&#x27;</span>, <span class="number">0</span>, <span class="number">1.0</span>, step=<span class="number">0.05</span>),</span><br><span class="line">        <span class="string">&quot;gamma&quot;</span>: trial.suggest_float(<span class="string">&quot;gamma&quot;</span>, <span class="number">0</span>, <span class="number">0.1</span>, step=<span class="number">0.0005</span>),</span><br><span class="line">        <span class="string">&quot;min_child_weight&quot;</span>: trial.suggest_int(<span class="string">&quot;min_child_weight&quot;</span>, <span class="number">0</span>, <span class="number">10</span>),</span><br><span class="line">        <span class="string">&#x27;nthread&#x27;</span>: -<span class="number">1</span>,</span><br><span class="line">        <span class="string">&#x27;booster&#x27;</span>: <span class="string">&quot;gbtree&quot;</span>,</span><br><span class="line">        <span class="string">&#x27;objective&#x27;</span>: <span class="string">&quot;reg:squarederror&quot;</span>,</span><br><span class="line">        <span class="string">&#x27;early_stopping_rounds&#x27;</span>: <span class="number">300</span>,</span><br><span class="line">        <span class="string">&#x27;random_state&#x27;</span>: <span class="number">42</span>,</span><br><span class="line">        <span class="string">&#x27;eval_metric&#x27;</span>: <span class="string">&quot;rmse&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Tune pruning</span></span><br><span class="line">    <span class="comment"># from optuna.integration import XGBoostPruningCallback</span></span><br><span class="line">    <span class="comment"># pruning_callback = XGBoostPruningCallback(trial, &quot;validation_0-rmse&quot;)</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    model = xgb.XGBRegressor(</span><br><span class="line">        <span class="comment"># callbacks=[pruning_callback],</span></span><br><span class="line">        **params</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Check and enable GPU accelerate</span></span><br><span class="line">    GPU_ENABLED = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">if</span> GPU_ENABLED:</span><br><span class="line">        params[<span class="string">&quot;tree_method&quot;</span>] = <span class="string">&quot;gpu_hist&quot;</span></span><br><span class="line">        params[<span class="string">&quot;predictor&quot;</span>] = <span class="string">&quot;gpu_predictor&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># K-Fold CV</span></span><br><span class="line">    kf = KFold(n_splits=<span class="number">5</span>, shuffle=<span class="literal">True</span>, random_state=<span class="number">2022</span>)</span><br><span class="line">    kf.split(X_train, y_train)</span><br><span class="line">    rmse = []</span><br><span class="line">    <span class="keyword">for</span> train_index, valid_index <span class="keyword">in</span> kf.split(X_train, y_train):</span><br><span class="line">        X_trainS, X_validS = X_train.iloc[train_index], X_train.iloc[valid_index]</span><br><span class="line">        y_trainS, y_validS = y_train.iloc[train_index], y_train.iloc[valid_index]</span><br><span class="line">        X_trainS = preprocess.fit_transform(X_trainS, y_trainS)</span><br><span class="line">        X_validS = preprocess.transform(X_validS)</span><br><span class="line"></span><br><span class="line">        model.fit(</span><br><span class="line">            X_trainS,</span><br><span class="line">            y_trainS,</span><br><span class="line">            eval_set=[(X_validS, y_validS)],</span><br><span class="line">            verbose=<span class="literal">False</span></span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        yhat = model.predict(X_validS)</span><br><span class="line">        rmse.append(mean_squared_error(y_validS, yhat, squared=<span class="literal">False</span>))</span><br><span class="line">    rmse = <span class="built_in">sum</span>(rmse) / <span class="built_in">len</span>(rmse)</span><br><span class="line">    <span class="keyword">return</span> rmse</span><br><span class="line"></span><br><span class="line">study_xgb = optuna.create_study(study_name=<span class="string">&quot;XGB Tuner&quot;</span>, direction=<span class="string">&quot;minimize&quot;</span>)</span><br><span class="line">study_xgb.optimize(</span><br><span class="line">    <span class="keyword">lambda</span> trial: objective_xgb(</span><br><span class="line">        trial,</span><br><span class="line">        X_train,</span><br><span class="line">        y_train_raw),</span><br><span class="line">    n_trials=<span class="number">300</span>)</span><br><span class="line">xgbBestPara = study_xgb.best_params</span><br><span class="line"><span class="built_in">print</span>(</span><br><span class="line">    <span class="string">f&#x27;Best Parameter: <span class="subst">&#123;study_xgb.best_params&#125;</span>\nBest Score: <span class="subst">&#123;study_xgb.best_value&#125;</span>&#x27;</span>)</span><br><span class="line">	</span><br><span class="line"><span class="comment"># Best Parameter: &#123;&#x27;n_estimators&#x27;: 3294, &#x27;reg_alpha&#x27;: 1.929897932989974e-10, &#x27;reg_lambda&#x27;: 1.0186659359903715e-07, &#x27;subsample&#x27;: 0.8460000000000001, &#x27;learning_rate&#x27;: 0.0123668789206247, &#x27;max_depth&#x27;: 3, &#x27;colsample_bytree&#x27;: 0.30000000000000004, &#x27;colsample_bylevel&#x27;: 0.6000000000000001, &#x27;colsample_bynode&#x27;: 0.75, &#x27;gamma&#x27;: 0.007, &#x27;min_child_weight&#x27;: 0&#125;</span></span><br><span class="line"><span class="comment"># Best Score: 0.11385928560228975</span></span><br></pre></td></tr></table></figure>

<h3 id="随机森林模型"><a href="#随机森林模型" class="headerlink" title="随机森林模型"></a>随机森林模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">objective_rf</span>(<span class="params">trial, X_train, y_train_raw</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Objective function to tune an `RandomForestRegressor` model.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    y_train = np.log1p(y_train_raw)</span><br><span class="line"></span><br><span class="line">    params = &#123;</span><br><span class="line">        <span class="string">&#x27;n_estimators&#x27;</span>: trial.suggest_int(<span class="string">&#x27;n_estimators&#x27;</span>, <span class="number">400</span>, <span class="number">800</span>),</span><br><span class="line">        <span class="string">&#x27;max_features&#x27;</span>: trial.suggest_uniform(<span class="string">&#x27;max_features&#x27;</span>, <span class="number">0.1</span>, <span class="number">0.5</span>),</span><br><span class="line">        <span class="string">&#x27;min_samples_split&#x27;</span>: trial.suggest_int(<span class="string">&#x27;min_samples_split&#x27;</span>, <span class="number">2</span>, <span class="number">5</span>),</span><br><span class="line">        <span class="string">&#x27;min_samples_leaf&#x27;</span>: trial.suggest_int(<span class="string">&#x27;min_samples_leaf&#x27;</span>, <span class="number">1</span>, <span class="number">5</span>),</span><br><span class="line">        <span class="string">&#x27;max_samples&#x27;</span>: trial.suggest_uniform(<span class="string">&#x27;max_samples&#x27;</span>, <span class="number">0.8</span>, <span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    model = RandomForestRegressor(n_jobs=-<span class="number">1</span>,</span><br><span class="line">                                  random_state=<span class="number">44</span>,</span><br><span class="line">                                  **params)</span><br><span class="line">    </span><br><span class="line">    modelP = Pipeline(steps = [(<span class="string">&quot;pre&quot;</span>, preprocess),</span><br><span class="line">                               (<span class="string">&quot;model&quot;</span>, model)</span><br><span class="line">                               ])</span><br><span class="line"></span><br><span class="line">    rmse = np.sqrt(-cross_val_score(modelP, X_train, y_train, </span><br><span class="line">                                    n_jobs=-<span class="number">1</span>, </span><br><span class="line">                                    cv=<span class="number">5</span>, </span><br><span class="line">                                    scoring=<span class="string">&quot;neg_mean_squared_error&quot;</span>)).mean()</span><br><span class="line">    <span class="keyword">return</span> rmse</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">study_rf = optuna.create_study(direction=<span class="string">&quot;minimize&quot;</span>)</span><br><span class="line">study_rf.optimize(</span><br><span class="line">    <span class="keyword">lambda</span> trial: objective_rf(</span><br><span class="line">        trial,</span><br><span class="line">        X_train,</span><br><span class="line">        y_train_raw),</span><br><span class="line">    n_trials=<span class="number">300</span>)</span><br><span class="line"></span><br><span class="line">rfBestPara = study_rf.best_params</span><br><span class="line"><span class="built_in">print</span>(</span><br><span class="line">    <span class="string">f&#x27;Best Parameter: <span class="subst">&#123;study_rf.best_params&#125;</span>\nBest Score: <span class="subst">&#123;study_rf.best_value&#125;</span>&#x27;</span>)</span><br><span class="line">	</span><br><span class="line"><span class="comment"># Best Parameter: &#123;&#x27;n_estimators&#x27;: 601, &#x27;max_features&#x27;: 0.2540470909182003, &#x27;min_samples_split&#x27;: 5, &#x27;min_samples_leaf&#x27;: 1, &#x27;max_samples&#x27;: 0.9999286526034251&#125;</span></span><br><span class="line"><span class="comment"># Best Score: 0.13323499907488073</span></span><br></pre></td></tr></table></figure>

<h3 id="轻量梯度上升模型"><a href="#轻量梯度上升模型" class="headerlink" title="轻量梯度上升模型"></a>轻量梯度上升模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">objective_lgb</span>(<span class="params">trial, X_train, y_train_raw</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Objective function to tune an `lgb` model.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    y_train = np.log1p(y_train_raw)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Define Parameter Grid to Tune</span></span><br><span class="line">    params = &#123;</span><br><span class="line">        <span class="string">&#x27;objective&#x27;</span>: <span class="string">&#x27;regression&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;metric&#x27;</span>: <span class="string">&#x27;rmse&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;verbosity&#x27;</span>: -<span class="number">1</span>,</span><br><span class="line">        <span class="string">&#x27;boosting_type&#x27;</span>: <span class="string">&#x27;gbdt&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;reg_alpha&#x27;</span>: trial.suggest_loguniform(<span class="string">&#x27;reg_alpha&#x27;</span>, <span class="number">1e-6</span>, <span class="number">1e-3</span>),</span><br><span class="line">        <span class="string">&#x27;reg_lambda&#x27;</span>: trial.suggest_loguniform(<span class="string">&#x27;reg_lambda&#x27;</span>, <span class="number">1e-8</span>, <span class="number">10.0</span>),</span><br><span class="line">        <span class="string">&#x27;num_leaves&#x27;</span>: trial.suggest_int(<span class="string">&#x27;num_leaves&#x27;</span>, <span class="number">2</span>, <span class="number">20</span>),</span><br><span class="line">        <span class="comment"># &#x27;learning_rate&#x27;: trial.suggest_loguniform(&#x27;learning_rate&#x27;, 1e-8, 1.0),</span></span><br><span class="line">        <span class="string">&#x27;learning_rate&#x27;</span>: <span class="number">0.01</span>,</span><br><span class="line">        <span class="string">&#x27;n_estimators&#x27;</span>: trial.suggest_int(<span class="string">&#x27;n_estimators&#x27;</span>, <span class="number">4500</span>, <span class="number">8500</span>),</span><br><span class="line">        <span class="string">&#x27;colsample_bytree&#x27;</span>: trial.suggest_uniform(<span class="string">&#x27;colsample_bytree&#x27;</span>, <span class="number">0.8</span>, <span class="number">0.9</span>),</span><br><span class="line">        <span class="string">&#x27;subsample&#x27;</span>: trial.suggest_uniform(<span class="string">&#x27;subsample&#x27;</span>, <span class="number">0.001</span>, <span class="number">1.0</span>),</span><br><span class="line">        <span class="comment">#&#x27;bagging_freq&#x27;: trial.suggest_int(&#x27;bagging_freq&#x27;, 1, 7),</span></span><br><span class="line">        <span class="string">&#x27;min_child_samples&#x27;</span>: trial.suggest_int(<span class="string">&#x27;min_child_samples&#x27;</span>, <span class="number">1</span>, <span class="number">5</span>)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Tune pruning</span></span><br><span class="line">    <span class="comment"># from optuna.integration import LightGBMPruningCallback</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># pruning_callback = LightGBMPruningCallback(trial, &quot;rmse&quot;)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    model = lgb.LGBMRegressor(</span><br><span class="line">        random_state=<span class="number">42</span>,</span><br><span class="line">        **params</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    callbacks = [lgb.early_stopping(<span class="number">300</span>, verbose=<span class="number">0</span>), </span><br><span class="line">                 lgb.log_evaluation(period=<span class="number">0</span>), </span><br><span class="line">                <span class="comment">#  pruning_callback</span></span><br><span class="line">                 ]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># K-Fold CV</span></span><br><span class="line">    kf = KFold(n_splits=<span class="number">5</span>, shuffle=<span class="literal">True</span>, random_state=<span class="number">2022</span>)</span><br><span class="line">    kf.split(X_train, y_train)</span><br><span class="line">    rmse = []</span><br><span class="line">    <span class="keyword">for</span> train_index, valid_index <span class="keyword">in</span> kf.split(X_train, y_train):</span><br><span class="line">        X_trainS, X_validS = X_train.iloc[train_index], X_train.iloc[valid_index]</span><br><span class="line">        y_trainS, y_validS = y_train.iloc[train_index], y_train.iloc[valid_index]</span><br><span class="line">        X_trainS = preprocess.fit_transform(X_trainS, y_trainS)</span><br><span class="line">        X_validS = preprocess.transform(X_validS)</span><br><span class="line"></span><br><span class="line">        model.fit(</span><br><span class="line">            X_trainS,</span><br><span class="line">            y_trainS,</span><br><span class="line">            eval_set=[(X_validS, y_validS)],</span><br><span class="line">            callbacks=callbacks</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        yhat = model.predict(X_validS)</span><br><span class="line">        rmse.append(mean_squared_error(y_validS, yhat, squared=<span class="literal">False</span>))</span><br><span class="line">    rmse = <span class="built_in">sum</span>(rmse) / <span class="built_in">len</span>(rmse)</span><br><span class="line">    <span class="keyword">return</span> rmse</span><br><span class="line"></span><br><span class="line">study_lgb = optuna.create_study(direction=<span class="string">&quot;minimize&quot;</span>)</span><br><span class="line">study_lgb.optimize(</span><br><span class="line">    <span class="keyword">lambda</span> trial: objective_lgb(</span><br><span class="line">        trial,</span><br><span class="line">        X_train,</span><br><span class="line">        y_train_raw),</span><br><span class="line">    n_trials=<span class="number">300</span>)</span><br><span class="line">lgbBestPara = study_lgb.best_params</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Best Parameter: <span class="subst">&#123;study_lgb.best_params&#125;</span>\nBest Score: <span class="subst">&#123;study_lgb.best_value&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Best Parameter: &#123;&#x27;reg_alpha&#x27;: 2.440166117521566e-05, &#x27;reg_lambda&#x27;: 0.006869171906469875, &#x27;num_leaves&#x27;: 4, &#x27;n_estimators&#x27;: 6623, &#x27;colsample_bytree&#x27;: 0.8246153451262771, &#x27;subsample&#x27;: 0.39754188623980913, &#x27;min_child_samples&#x27;: 3&#125;</span></span><br><span class="line"><span class="comment"># Best Score: 0.11849003568984647</span></span><br></pre></td></tr></table></figure>

<h3 id="弹力网回归模型"><a href="#弹力网回归模型" class="headerlink" title="弹力网回归模型"></a>弹力网回归模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> ElasticNet</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">objective_elas</span>(<span class="params">trial, X_train, y_train_raw</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Objective function to tune an `ElasticNet` model.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    y_train = np.log1p(y_train_raw)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Define Parameter Grid to Tune</span></span><br><span class="line">    params = &#123;</span><br><span class="line">        <span class="string">&#x27;alpha&#x27;</span>: trial.suggest_loguniform(<span class="string">&#x27;alpha&#x27;</span>, <span class="number">0.001</span>, <span class="number">1</span>),</span><br><span class="line">        <span class="string">&#x27;l1_ratio&#x27;</span>: trial.suggest_loguniform(<span class="string">&#x27;l1_ratio&#x27;</span>, <span class="number">0.001</span>, <span class="number">0.2</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    model = ElasticNet(</span><br><span class="line">        random_state=<span class="number">44</span>,</span><br><span class="line">        max_iter=<span class="number">100000000</span>,</span><br><span class="line">        **params</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># K-Fold CV</span></span><br><span class="line">    kf = KFold(n_splits=<span class="number">5</span>, shuffle=<span class="literal">True</span>, random_state=<span class="number">2022</span>)</span><br><span class="line">    kf.split(X_train, y_train)</span><br><span class="line">    rmse = []</span><br><span class="line">    <span class="keyword">for</span> train_index, valid_index <span class="keyword">in</span> kf.split(X_train, y_train):</span><br><span class="line">        X_trainS, X_validS = X_train.iloc[train_index], X_train.iloc[valid_index]</span><br><span class="line">        y_trainS, y_validS = y_train.iloc[train_index], y_train.iloc[valid_index]</span><br><span class="line">        X_trainS = preprocess.fit_transform(X_trainS, y_trainS)</span><br><span class="line">        X_validS = preprocess.transform(X_validS)</span><br><span class="line"></span><br><span class="line">        model.fit(</span><br><span class="line">            X_trainS,</span><br><span class="line">            y_trainS</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        yhat = model.predict(X_validS)</span><br><span class="line">        rmse.append(mean_squared_error(y_validS, yhat, squared=<span class="literal">False</span>))</span><br><span class="line">    rmse = <span class="built_in">sum</span>(rmse) / <span class="built_in">len</span>(rmse)</span><br><span class="line">    <span class="keyword">return</span> rmse</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">study_elas = optuna.create_study(direction=<span class="string">&quot;minimize&quot;</span>)</span><br><span class="line">study_elas.optimize(</span><br><span class="line">    <span class="keyword">lambda</span> trial: objective_elas(</span><br><span class="line">        trial,</span><br><span class="line">        X_train,</span><br><span class="line">        y_train_raw),</span><br><span class="line">    n_trials=<span class="number">300</span></span><br><span class="line">    )</span><br><span class="line">elasBestPara = study_elas.best_params</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Best Parameter: <span class="subst">&#123;study_elas.best_params&#125;</span>\nBest Score: <span class="subst">&#123;study_elas.best_value&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Best Parameter: &#123;&#x27;alpha&#x27;: 0.05413710739105013, &#x27;l1_ratio&#x27;: 0.019619883123773534&#125;</span></span><br><span class="line"><span class="comment"># Best Score: 0.1441800147792022</span></span><br></pre></td></tr></table></figure>

<h3 id="套索回归模型"><a href="#套索回归模型" class="headerlink" title="套索回归模型"></a>套索回归模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">objective_lasso</span>(<span class="params">trial, X_train, y_train_raw</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Objective function to tune an `Lasso` model.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    y_train = np.log1p(y_train_raw)</span><br><span class="line"></span><br><span class="line">    model = Lasso(</span><br><span class="line">        max_iter=<span class="number">10000000</span>,</span><br><span class="line">        alpha=trial.suggest_loguniform(<span class="string">&#x27;alpha&#x27;</span>, <span class="number">1e-4</span>, <span class="number">2e-3</span>)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># K-Fold CV</span></span><br><span class="line">    kf = KFold(n_splits=<span class="number">5</span>, shuffle=<span class="literal">True</span>, random_state=<span class="number">2022</span>)</span><br><span class="line">    kf.split(X_train, y_train)</span><br><span class="line">    rmse = []</span><br><span class="line">    <span class="keyword">for</span> train_index, valid_index <span class="keyword">in</span> kf.split(X_train, y_train):</span><br><span class="line">        X_trainS, X_validS = X_train.iloc[train_index], X_train.iloc[valid_index]</span><br><span class="line">        y_trainS, y_validS = y_train.iloc[train_index], y_train.iloc[valid_index]</span><br><span class="line">        X_trainS = preprocess.fit_transform(X_trainS, y_trainS)</span><br><span class="line">        X_validS = preprocess.transform(X_validS)</span><br><span class="line"></span><br><span class="line">        model.fit(</span><br><span class="line">            X_trainS,</span><br><span class="line">            y_trainS</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        yhat = model.predict(X_validS)</span><br><span class="line">        rmse.append(mean_squared_error(y_validS, yhat, squared=<span class="literal">False</span>))</span><br><span class="line">    rmse = <span class="built_in">sum</span>(rmse) / <span class="built_in">len</span>(rmse)</span><br><span class="line">    <span class="keyword">return</span> rmse</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">study_lasso = optuna.create_study(direction=<span class="string">&quot;minimize&quot;</span>)</span><br><span class="line">study_lasso.optimize(</span><br><span class="line">    <span class="keyword">lambda</span> trial: objective_lasso(</span><br><span class="line">        trial,</span><br><span class="line">        X_train,</span><br><span class="line">        y_train_raw),</span><br><span class="line">    n_trials=<span class="number">300</span></span><br><span class="line">    )</span><br><span class="line">lassoBestPara = study_lasso.best_params</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Best Parameter: <span class="subst">&#123;study_lasso.best_params&#125;</span>\nBest Score: <span class="subst">&#123;study_lasso.best_value&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Best Parameter: &#123;&#x27;alpha&#x27;: 0.001211363074795742&#125;</span></span><br><span class="line"><span class="comment"># Best Score: 0.14435096531753505</span></span><br></pre></td></tr></table></figure>

<h3 id="岭回归模型"><a href="#岭回归模型" class="headerlink" title="岭回归模型"></a>岭回归模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">objective_ridge</span>(<span class="params">trial, X_train, y_train_raw</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Objective function to tune an `Ridge` model.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    y_train = np.log1p(y_train_raw)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Define Parameter Grid to Tune</span></span><br><span class="line">    params = &#123;</span><br><span class="line">        <span class="string">&#x27;alpha&#x27;</span>: trial.suggest_loguniform(<span class="string">&#x27;alpha&#x27;</span>, <span class="number">94</span>, <span class="number">98</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    model = Ridge(</span><br><span class="line">        **params</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># K-Fold CV</span></span><br><span class="line">    kf = KFold(n_splits=<span class="number">5</span>, shuffle=<span class="literal">True</span>, random_state=<span class="number">2022</span>)</span><br><span class="line">    kf.split(X_train, y_train)</span><br><span class="line">    rmse = []</span><br><span class="line">    <span class="keyword">for</span> train_index, valid_index <span class="keyword">in</span> kf.split(X_train, y_train):</span><br><span class="line">        X_trainS, X_validS = X_train.iloc[train_index], X_train.iloc[valid_index]</span><br><span class="line">        y_trainS, y_validS = y_train.iloc[train_index], y_train.iloc[valid_index]</span><br><span class="line">        X_trainS = preprocess.fit_transform(X_trainS, y_trainS)</span><br><span class="line">        X_validS = preprocess.transform(X_validS)</span><br><span class="line"></span><br><span class="line">        model.fit(</span><br><span class="line">            X_trainS,</span><br><span class="line">            y_trainS</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        yhat = model.predict(X_validS)</span><br><span class="line">        rmse.append(mean_squared_error(y_validS, yhat, squared=<span class="literal">False</span>))</span><br><span class="line">    rmse = <span class="built_in">sum</span>(rmse) / <span class="built_in">len</span>(rmse)</span><br><span class="line">    <span class="keyword">return</span> rmse</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">study_ridge = optuna.create_study(direction=<span class="string">&quot;minimize&quot;</span>)</span><br><span class="line">study_ridge.optimize(</span><br><span class="line">    <span class="keyword">lambda</span> trial: objective_ridge(</span><br><span class="line">        trial,</span><br><span class="line">        X_train,</span><br><span class="line">        y_train_raw),</span><br><span class="line">    n_trials=<span class="number">300</span></span><br><span class="line">    )</span><br><span class="line">ridgeBestPara = study_ridge.best_params</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Best Parameter: <span class="subst">&#123;study_ridge.best_params&#125;</span>\nBest Score: <span class="subst">&#123;study_ridge.best_value&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Best Parameter: &#123;&#x27;alpha&#x27;: 96.39298499008997&#125;</span></span><br><span class="line"><span class="comment"># Best Score: 0.14449888940471906</span></span><br></pre></td></tr></table></figure>

<hr>
<h2 id="模型堆叠与混合"><a href="#模型堆叠与混合" class="headerlink" title="模型堆叠与混合"></a>模型堆叠与混合</h2><h3 id="模型堆叠-Stacking"><a href="#模型堆叠-Stacking" class="headerlink" title="模型堆叠(Stacking)"></a>模型堆叠(Stacking)</h3><p>在上述的模型中，极限梯度上升XGB的实测性能最好，然而，为了让其它的模型也能用到，这里我们考虑将所有上述模型进行堆叠，将他们用为一层基线模型，然后用岭回归作为二层元模型。我们使用<code>StackingRegressor</code>来实现。</p>
<p>首先将所有调到的最优参数储存，并搭建每一个模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">xgbBestPara = &#123;<span class="string">&#x27;n_estimators&#x27;</span>: <span class="number">3294</span>, </span><br><span class="line">               <span class="string">&#x27;reg_alpha&#x27;</span>: <span class="number">1.929897932989974e-10</span>,</span><br><span class="line">               <span class="string">&#x27;reg_lambda&#x27;</span>: <span class="number">1.0186659359903715e-07</span>, </span><br><span class="line">               <span class="string">&#x27;subsample&#x27;</span>: <span class="number">0.8460000000000001</span>,</span><br><span class="line">               <span class="string">&#x27;learning_rate&#x27;</span>: <span class="number">0.0123668789206247</span>,</span><br><span class="line">               <span class="string">&#x27;max_depth&#x27;</span>: <span class="number">3</span>, </span><br><span class="line">               <span class="string">&#x27;colsample_bytree&#x27;</span>: <span class="number">0.30000000000000004</span>, </span><br><span class="line">               <span class="string">&#x27;colsample_bylevel&#x27;</span>: <span class="number">0.6000000000000001</span>,</span><br><span class="line">               <span class="string">&#x27;colsample_bynode&#x27;</span>: <span class="number">0.75</span>,</span><br><span class="line">               <span class="string">&#x27;gamma&#x27;</span>: <span class="number">0.007</span>, </span><br><span class="line">               <span class="string">&#x27;min_child_weight&#x27;</span>: <span class="number">0</span>&#125;</span><br><span class="line"></span><br><span class="line">lgbBestPara = &#123;<span class="string">&#x27;reg_alpha&#x27;</span>: <span class="number">2.440166117521566e-05</span>,</span><br><span class="line">               <span class="string">&#x27;reg_lambda&#x27;</span>: <span class="number">0.006869171906469875</span>,</span><br><span class="line">               <span class="string">&#x27;num_leaves&#x27;</span>: <span class="number">4</span>,</span><br><span class="line">               <span class="string">&#x27;n_estimators&#x27;</span>: <span class="number">6623</span>,</span><br><span class="line">               <span class="string">&#x27;colsample_bytree&#x27;</span>: <span class="number">0.8246153451262771</span>,</span><br><span class="line">               <span class="string">&#x27;subsample&#x27;</span>: <span class="number">0.39754188623980913</span>,</span><br><span class="line">               <span class="string">&#x27;min_child_samples&#x27;</span>: <span class="number">3</span>&#125;</span><br><span class="line"></span><br><span class="line">elasBestPara = &#123;<span class="string">&#x27;alpha&#x27;</span>: <span class="number">0.05413710739105013</span>, </span><br><span class="line">                <span class="string">&#x27;l1_ratio&#x27;</span>: <span class="number">0.019619883123773534</span>&#125;</span><br><span class="line"></span><br><span class="line">rfBestPara = &#123;<span class="string">&#x27;n_estimators&#x27;</span>: <span class="number">601</span>,</span><br><span class="line">              <span class="string">&#x27;max_features&#x27;</span>: <span class="number">0.2540470909182003</span>,</span><br><span class="line">              <span class="string">&#x27;min_samples_split&#x27;</span>: <span class="number">5</span>,</span><br><span class="line">              <span class="string">&#x27;min_samples_leaf&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">              <span class="string">&#x27;max_samples&#x27;</span>: <span class="number">0.9999286526034251</span>&#125;</span><br><span class="line"></span><br><span class="line">ridgeBestPara = &#123;<span class="string">&#x27;alpha&#x27;</span>: <span class="number">96.39298499008997</span>&#125;</span><br><span class="line"></span><br><span class="line">lassoBestPara = &#123;<span class="string">&#x27;alpha&#x27;</span>: <span class="number">0.001211363074795742</span>&#125;</span><br><span class="line"></span><br><span class="line">modelXGB = Pipeline(steps=[(<span class="string">&quot;pre&quot;</span>, preprocess),</span><br><span class="line">                           (<span class="string">&quot;model&quot;</span>, xgb.XGBRegressor(</span><br><span class="line">                               booster=<span class="string">&quot;gbtree&quot;</span>,</span><br><span class="line">                               objective=<span class="string">&quot;reg:squarederror&quot;</span>,</span><br><span class="line">                               random_state=<span class="number">42</span>,</span><br><span class="line">                               **xgbBestPara</span><br><span class="line">                           ))</span><br><span class="line">                           ])</span><br><span class="line"></span><br><span class="line">modelLGB = Pipeline(steps=[(<span class="string">&quot;pre&quot;</span>, preprocess),</span><br><span class="line">                           (<span class="string">&quot;model&quot;</span>, lgb.LGBMRegressor(</span><br><span class="line">                               random_state=<span class="number">42</span>,</span><br><span class="line">                               **lgbBestPara</span><br><span class="line">                           ))</span><br><span class="line">                           ])</span><br><span class="line"></span><br><span class="line">modelElastic = Pipeline(steps=[(<span class="string">&quot;pre&quot;</span>, preprocess),</span><br><span class="line">                               (<span class="string">&quot;model&quot;</span>, ElasticNet(</span><br><span class="line">                                   random_state=<span class="number">44</span>,</span><br><span class="line">                                   max_iter=<span class="number">100000000</span>,</span><br><span class="line">                                   **elasBestPara</span><br><span class="line">                               ))</span><br><span class="line">                               ])</span><br><span class="line"></span><br><span class="line">modelRf = Pipeline(steps=[(<span class="string">&quot;pre&quot;</span>, preprocess),</span><br><span class="line">                          (<span class="string">&quot;model&quot;</span>, RandomForestRegressor(</span><br><span class="line">                              n_jobs=-<span class="number">1</span>,</span><br><span class="line">                              random_state=<span class="number">44</span>,</span><br><span class="line">                              **rfBestPara</span><br><span class="line">                          ))</span><br><span class="line">                          ])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">modelRidge = Pipeline(steps=[(<span class="string">&quot;pre&quot;</span>, preprocess),</span><br><span class="line">                             (<span class="string">&quot;model&quot;</span>, Ridge(</span><br><span class="line">                              **ridgeBestPara</span><br><span class="line">                              ))</span><br><span class="line">                             ])</span><br><span class="line"></span><br><span class="line">modelLasso = Pipeline(steps=[(<span class="string">&quot;pre&quot;</span>, preprocess),</span><br><span class="line">                             (<span class="string">&quot;model&quot;</span>, Lasso(</span><br><span class="line">                                 max_iter=<span class="number">10000000</span>,</span><br><span class="line">                                 **lassoBestPara))</span><br><span class="line">                             ])</span><br></pre></td></tr></table></figure>

<p>然后进行堆叠：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> StackingRegressor</span><br><span class="line"></span><br><span class="line">estimators = [(<span class="string">&#x27;xgb&#x27;</span>, modelXGB),</span><br><span class="line">              (<span class="string">&#x27;lgb&#x27;</span>, modelLGB),</span><br><span class="line">              (<span class="string">&#x27;elastic&#x27;</span>, modelElastic),</span><br><span class="line">              (<span class="string">&#x27;rf&#x27;</span>, modelRf),</span><br><span class="line">              (<span class="string">&#x27;lasso&#x27;</span>, modelLasso),</span><br><span class="line">              (<span class="string">&#x27;ridge&#x27;</span>, modelRidge)</span><br><span class="line">              ]</span><br><span class="line">reg = StackingRegressor(estimators=estimators,</span><br><span class="line">                        n_jobs=-<span class="number">1</span>,</span><br><span class="line">                        verbose=<span class="number">2</span>,</span><br><span class="line">                        cv=<span class="number">5</span>,</span><br><span class="line">                        final_estimator=Ridge(max_iter=<span class="number">10000000</span>)</span><br><span class="line">                        )</span><br><span class="line">y_train = np.log1p(y_train_raw)</span><br><span class="line"></span><br><span class="line">reg.fit(X_train, y_train)</span><br><span class="line">y_pred = np.expm1(reg.predict(X_test))</span><br></pre></td></tr></table></figure>

<p>堆叠出来的模型实测有所提升，大概提升了40名左右。</p>
<h3 id="模型混合-Blending"><a href="#模型混合-Blending" class="headerlink" title="模型混合(Blending)"></a>模型混合(Blending)</h3><p>做完堆叠后，我们可以考虑将堆叠模型和其他所有模型进行混合，即每个模型分别做预测，然后按一定权重进行混合，得到最终结果。某种意义上，这个和上述的堆叠的二层元模型做的事情很像（如果元模型选的是线性回归的话），但实测下来是有提升的，于是本人也就懒得去探讨其具体的区别了，先用上再说。当然这里的权重是本人随便设置的，不是很严谨，最好的是根据测试集进行调整，但由于时间原因，就不在这个项目里做了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">BlendingModel</span>(<span class="params">X_train, y_train, X_test</span>):</span><br><span class="line">    xgbPredict = modelXGB.fit(X_train, y_train).predict(X_test)</span><br><span class="line">    lgbPredict = modelLGB.fit(X_train, y_train).predict(X_test)</span><br><span class="line">    elasticPred = modelElastic.fit(X_train, y_train).predict(X_test)</span><br><span class="line">    rfPred = modelRf.fit(X_train, y_train).predict(X_test)</span><br><span class="line">    lassoPred = modelLasso.fit(X_train, y_train).predict(X_test)</span><br><span class="line">    ridgePred = modelRidge.fit(X_train, y_train).predict(X_test)</span><br><span class="line"></span><br><span class="line">    stackPred = reg.fit(X_train, y_train).predict(X_test)</span><br><span class="line">    blended_pred = (<span class="number">0.05</span>*xgbPredict +</span><br><span class="line">                    <span class="number">0.1</span>*lgbPredict +</span><br><span class="line">                    <span class="number">0.05</span>*elasticPred +</span><br><span class="line">                    <span class="number">0</span>*rfPred +</span><br><span class="line">                    <span class="number">0.05</span>*lassoPred +</span><br><span class="line">                    <span class="number">0.04</span>*ridgePred +</span><br><span class="line">                    <span class="number">0.71</span>*stackPred</span><br><span class="line">                    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> blended_pred</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">blend_pred = np.expm1(BlendingModel(X_train, y_train, X_test))</span><br></pre></td></tr></table></figure>

<p>这一步做完大概提升了100多名的样子。</p>
<hr>
<h2 id="结果输出"><a href="#结果输出" class="headerlink" title="结果输出"></a>结果输出</h2><p>最终提交给Kaggle的数据需要根据其要求进行格式化，这一步就是很基础的表操作，不细说了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">BLENDcsv = test_raw.copy()</span><br><span class="line">BLENDcsv[<span class="string">&#x27;SalePrice&#x27;</span>] = blend_pred</span><br><span class="line">BLENDcsv[<span class="string">&#x27;Id&#x27;</span>] = test_ID</span><br><span class="line">BLENDcsv[[<span class="string">&#x27;Id&#x27;</span>, <span class="string">&#x27;SalePrice&#x27;</span>]].set_index(<span class="string">&#x27;Id&#x27;</span>).to_csv(<span class="string">&#x27;BLEND.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>将csv提交后便可以得到成绩啦！</p>
<img src="/posts/32983/resultSCU.png" class="" title="Result">

<p>这个排名和大佬总归是不能比的，但作为一个刚入门的新手，本人觉得能拿到Top15%就已经可以接受了。当然其实这个名次是可以优化的，主要就是上述的模型混合部分，具体权重我认为是还有些操作空间的，这就留给未来再说吧，目前这个成绩就足以应付课程期末了。</p>
<link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>
    </div>

    
    
    

    <footer class="post-footer">
          <div class="reward-container">
  <div>请我一杯咖啡吧！</div>
  <button>
    赞赏
  </button>
  <div class="post-reward">
      <div>
        <img src="/images/Sponsor/wechat.png" alt="分数受害者 微信">
        <span>微信</span>
      </div>
      <div>
        <img src="/images/Sponsor/alipay.jpg" alt="分数受害者 支付宝">
        <span>支付宝</span>
      </div>

  </div>
</div>

          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>原作者： </strong>分数受害者
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://scorevictim.github.io/posts/32983/" title="机器学习期末Kaggle项目实践 —— House Prices - Advanced Regression Techniques">https://scorevictim.github.io/posts/32983/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="followme">
  <span>欢迎关注我的其它发布渠道</span>

  <div class="social-list">

      <div class="social-item">
          <a target="_blank" class="social-link" href="/atom.xml">
            <span class="icon">
              <i class="fa fa-rss"></i>
            </span>

            <span class="label">RSS</span>
          </a>
      </div>
  </div>
</div>

          <div class="post-tags">
              <a href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" rel="tag"># 数据分析</a>
              <a href="/tags/%E5%BB%BA%E6%A8%A1/" rel="tag"># 建模</a>
              <a href="/tags/python/" rel="tag"># python</a>
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
              <a href="/tags/%E9%A1%B9%E7%9B%AE/" rel="tag"># 项目</a>
              <a href="/tags/project/" rel="tag"># project</a>
              <a href="/tags/Kaggle/" rel="tag"># Kaggle</a>
              <a href="/tags/%E8%B0%83%E5%8F%82/" rel="tag"># 调参</a>
              <a href="/tags/optuna/" rel="tag"># optuna</a>
              <a href="/tags/regression/" rel="tag"># regression</a>
              <a href="/tags/%E5%9B%9E%E5%BD%92/" rel="tag"># 回归</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/posts/47643/" rel="prev" title="《红玫瑰》吉他谱">
                  <i class="fa fa-angle-left"></i> 《红玫瑰》吉他谱
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/posts/34883/" rel="next" title="在Windows10下为Tensorflow开启GPU加速">
                  在Windows10下为Tensorflow开启GPU加速 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments utterances-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2022 – 
    <span itemprop="copyrightYear">2023</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">分数受害者</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">204k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">3:06</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="/js/pjax.js"></script>

  




  <script src="/js/third-party/pace.js"></script>


  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


  <script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":true,"delay":true,"timeout":3000,"priority":true,"url":"https://scorevictim.github.io/posts/32983/"}</script>
  <script src="/js/third-party/quicklink.js"></script>
<script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"scorevictim/blogcomments","issue_term":"title","theme":"github-dark"}</script>
<script src="/js/third-party/comments/utterances.js"></script>

</body>
</html>
